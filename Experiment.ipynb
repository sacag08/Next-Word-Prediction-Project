{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Word Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Projects\\Next Word Prediction using LSTM\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\sachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet.txt','w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing and Tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('hamlet.txt','r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "### Tokeniz the text - Creating the index for words\n",
    "tockenize = Tokenizer()\n",
    "tockenize.fit_on_texts([text])\n",
    "total_words = len(tockenize.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[407, 1182, 63]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tockenize.texts_to_sequences([\"Barnardo. Who's there?\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an input statatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tockenize.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 687],\n",
       " [1, 687, 4],\n",
       " [1, 687, 4, 45],\n",
       " [1, 687, 4, 45, 41],\n",
       " [1, 687, 4, 45, 41, 1886],\n",
       " [1, 687, 4, 45, 41, 1886, 1887],\n",
       " [1, 687, 4, 45, 41, 1886, 1887, 1888],\n",
       " [1180, 1889],\n",
       " [1180, 1889, 1890],\n",
       " [1180, 1889, 1890, 1891]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad Sequence\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1,  687],\n",
       "       [   0,    0,    0, ...,    1,  687,    4],\n",
       "       [   0,    0,    0, ...,  687,    4,   45],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,   45, 1047],\n",
       "       [   0,    0,    0, ...,   45, 1047,    4],\n",
       "       [   0,    0,    0, ..., 1047,    4,  193]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(input_sequences,maxlen=max_sequence_length,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(pad_sequences(input_sequences,maxlen=max_sequence_length,padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y = tf.keras.utils.to_categorical(y,num_classes = total_words)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GRU RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout,GRU\n",
    "\n",
    "#Define the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words,100,input_length = max_sequence_length-1))\n",
    "model.add(GRU(150,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100))\n",
    "model.add(Dense(total_words,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='loss',patience=5,restore_best_weights=True)\n",
    "check_point = ModelCheckpoint(\"gru1.h5\",monitor=\"loss\",save_best_only = True,model = \"auto\",verbose=1)\n",
    "reduced = ReduceLROnPlateau(monitor = \"loss\",factor=0.2,patience=3,min_lr = 0.0001,verbose=1)\n",
    "logdir=\"logs\"\n",
    "tensor_board_visualizations= TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 13, 150)           113400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 150)           0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 100)               75600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1157418 (4.42 MB)\n",
      "Trainable params: 1157418 (4.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model,to_file=\"model.png\",show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "640/644 [============================>.] - ETA: 0s - loss: 0.9023 - accuracy: 0.7869\n",
      "Epoch 1: loss improved from inf to 0.90199, saving model to gru1.h5\n",
      "644/644 [==============================] - 11s 14ms/step - loss: 0.9020 - accuracy: 0.7870 - val_loss: 12.1153 - val_accuracy: 0.0528 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "  9/644 [..............................] - ETA: 8s - loss: 0.8411 - accuracy: 0.7674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\Next Word Prediction using LSTM\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/644 [============================>.] - ETA: 0s - loss: 0.8655 - accuracy: 0.7886\n",
      "Epoch 2: loss improved from 0.90199 to 0.86609, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 13ms/step - loss: 0.8661 - accuracy: 0.7886 - val_loss: 12.1327 - val_accuracy: 0.0507 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.8521 - accuracy: 0.7877\n",
      "Epoch 3: loss improved from 0.86609 to 0.85250, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.8525 - accuracy: 0.7876 - val_loss: 12.2157 - val_accuracy: 0.0501 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.8411 - accuracy: 0.7919\n",
      "Epoch 4: loss improved from 0.85250 to 0.84126, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.8413 - accuracy: 0.7919 - val_loss: 12.2588 - val_accuracy: 0.0530 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.7917\n",
      "Epoch 5: loss did not improve from 0.84126\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.8430 - accuracy: 0.7917 - val_loss: 12.2927 - val_accuracy: 0.0525 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.8411 - accuracy: 0.7913\n",
      "Epoch 6: loss did not improve from 0.84126\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.8414 - accuracy: 0.7913 - val_loss: 12.3502 - val_accuracy: 0.0511 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.8418 - accuracy: 0.7902\n",
      "Epoch 7: loss did not improve from 0.84126\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.8423 - accuracy: 0.7902 - val_loss: 12.3838 - val_accuracy: 0.0499 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.7515 - accuracy: 0.8104\n",
      "Epoch 8: loss improved from 0.84126 to 0.75128, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 0.7513 - accuracy: 0.8104 - val_loss: 12.3961 - val_accuracy: 0.0527 - lr: 2.0000e-04\n",
      "Epoch 9/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.7213 - accuracy: 0.8177\n",
      "Epoch 9: loss improved from 0.75128 to 0.72122, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.7212 - accuracy: 0.8175 - val_loss: 12.3944 - val_accuracy: 0.0501 - lr: 2.0000e-04\n",
      "Epoch 10/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.7068 - accuracy: 0.8213\n",
      "Epoch 10: loss improved from 0.72122 to 0.70690, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.7069 - accuracy: 0.8213 - val_loss: 12.4034 - val_accuracy: 0.0511 - lr: 2.0000e-04\n",
      "Epoch 11/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6999 - accuracy: 0.8247\n",
      "Epoch 11: loss improved from 0.70690 to 0.70016, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 15ms/step - loss: 0.7002 - accuracy: 0.8245 - val_loss: 12.4240 - val_accuracy: 0.0517 - lr: 2.0000e-04\n",
      "Epoch 12/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.8253\n",
      "Epoch 12: loss improved from 0.70016 to 0.69554, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.6955 - accuracy: 0.8253 - val_loss: 12.4346 - val_accuracy: 0.0517 - lr: 2.0000e-04\n",
      "Epoch 13/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.8255\n",
      "Epoch 13: loss improved from 0.69554 to 0.68996, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 0.6900 - accuracy: 0.8255 - val_loss: 12.4379 - val_accuracy: 0.0528 - lr: 2.0000e-04\n",
      "Epoch 14/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.8267\n",
      "Epoch 14: loss improved from 0.68996 to 0.68568, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 0.6857 - accuracy: 0.8267 - val_loss: 12.4408 - val_accuracy: 0.0530 - lr: 2.0000e-04\n",
      "Epoch 15/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.8272\n",
      "Epoch 15: loss improved from 0.68568 to 0.68334, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.6833 - accuracy: 0.8272 - val_loss: 12.4481 - val_accuracy: 0.0527 - lr: 2.0000e-04\n",
      "Epoch 16/200\n",
      "640/644 [============================>.] - ETA: 0s - loss: 0.6800 - accuracy: 0.8267\n",
      "Epoch 16: loss improved from 0.68334 to 0.67884, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.6788 - accuracy: 0.8269 - val_loss: 12.4491 - val_accuracy: 0.0521 - lr: 2.0000e-04\n",
      "Epoch 17/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.8310\n",
      "Epoch 17: loss improved from 0.67884 to 0.67317, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 0.6732 - accuracy: 0.8310 - val_loss: 12.4595 - val_accuracy: 0.0523 - lr: 2.0000e-04\n",
      "Epoch 18/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.8296\n",
      "Epoch 18: loss improved from 0.67317 to 0.67140, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.6714 - accuracy: 0.8296 - val_loss: 12.4711 - val_accuracy: 0.0525 - lr: 2.0000e-04\n",
      "Epoch 19/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.8303\n",
      "Epoch 19: loss improved from 0.67140 to 0.67106, saving model to gru1.h5\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 0.6711 - accuracy: 0.8303 - val_loss: 12.4667 - val_accuracy: 0.0528 - lr: 2.0000e-04\n",
      "Epoch 20/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.8306\n",
      "Epoch 20: loss did not improve from 0.67106\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6721 - accuracy: 0.8306 - val_loss: 12.4696 - val_accuracy: 0.0544 - lr: 2.0000e-04\n",
      "Epoch 21/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6644 - accuracy: 0.8321\n",
      "Epoch 21: loss improved from 0.67106 to 0.66422, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 13ms/step - loss: 0.6642 - accuracy: 0.8322 - val_loss: 12.4801 - val_accuracy: 0.0517 - lr: 2.0000e-04\n",
      "Epoch 22/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.8330\n",
      "Epoch 22: loss improved from 0.66422 to 0.66293, saving model to gru1.h5\n",
      "644/644 [==============================] - 9s 13ms/step - loss: 0.6629 - accuracy: 0.8330 - val_loss: 12.4709 - val_accuracy: 0.0521 - lr: 2.0000e-04\n",
      "Epoch 23/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6638 - accuracy: 0.8300\n",
      "Epoch 23: loss did not improve from 0.66293\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6640 - accuracy: 0.8300 - val_loss: 12.4733 - val_accuracy: 0.0517 - lr: 2.0000e-04\n",
      "Epoch 24/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.8315\n",
      "Epoch 24: loss did not improve from 0.66293\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6641 - accuracy: 0.8314 - val_loss: 12.4772 - val_accuracy: 0.0519 - lr: 2.0000e-04\n",
      "Epoch 25/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.8341\n",
      "Epoch 25: loss improved from 0.66293 to 0.65512, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6551 - accuracy: 0.8341 - val_loss: 12.4870 - val_accuracy: 0.0528 - lr: 2.0000e-04\n",
      "Epoch 26/200\n",
      "640/644 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.8323\n",
      "Epoch 26: loss did not improve from 0.65512\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6565 - accuracy: 0.8323 - val_loss: 12.4901 - val_accuracy: 0.0544 - lr: 2.0000e-04\n",
      "Epoch 27/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6593 - accuracy: 0.8322\n",
      "Epoch 27: loss did not improve from 0.65512\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6596 - accuracy: 0.8321 - val_loss: 12.5035 - val_accuracy: 0.0525 - lr: 2.0000e-04\n",
      "Epoch 28/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6578 - accuracy: 0.8324\n",
      "Epoch 28: loss did not improve from 0.65512\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6579 - accuracy: 0.8323 - val_loss: 12.5074 - val_accuracy: 0.0527 - lr: 2.0000e-04\n",
      "Epoch 29/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.8353\n",
      "Epoch 29: loss improved from 0.65512 to 0.64602, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6460 - accuracy: 0.8353 - val_loss: 12.5105 - val_accuracy: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.8355\n",
      "Epoch 30: loss improved from 0.64602 to 0.64318, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6432 - accuracy: 0.8355 - val_loss: 12.5135 - val_accuracy: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6375 - accuracy: 0.8389\n",
      "Epoch 31: loss improved from 0.64318 to 0.63780, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6378 - accuracy: 0.8389 - val_loss: 12.5166 - val_accuracy: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6387 - accuracy: 0.8372\n",
      "Epoch 32: loss did not improve from 0.63780\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6390 - accuracy: 0.8371 - val_loss: 12.5169 - val_accuracy: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.8368\n",
      "Epoch 33: loss did not improve from 0.63780\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6422 - accuracy: 0.8368 - val_loss: 12.5239 - val_accuracy: 0.0538 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.8372\n",
      "Epoch 34: loss did not improve from 0.63780\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6402 - accuracy: 0.8372 - val_loss: 12.5229 - val_accuracy: 0.0538 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6344 - accuracy: 0.8363\n",
      "Epoch 35: loss improved from 0.63780 to 0.63397, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6340 - accuracy: 0.8364 - val_loss: 12.5282 - val_accuracy: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "643/644 [============================>.] - ETA: 0s - loss: 0.6306 - accuracy: 0.8396\n",
      "Epoch 36: loss improved from 0.63397 to 0.63048, saving model to gru1.h5\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6305 - accuracy: 0.8396 - val_loss: 12.5263 - val_accuracy: 0.0534 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "640/644 [============================>.] - ETA: 0s - loss: 0.6355 - accuracy: 0.8372\n",
      "Epoch 37: loss did not improve from 0.63048\n",
      "644/644 [==============================] - 9s 13ms/step - loss: 0.6362 - accuracy: 0.8373 - val_loss: 12.5305 - val_accuracy: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "641/644 [============================>.] - ETA: 0s - loss: 0.6370 - accuracy: 0.8366\n",
      "Epoch 38: loss did not improve from 0.63048\n",
      "644/644 [==============================] - 9s 14ms/step - loss: 0.6370 - accuracy: 0.8364 - val_loss: 12.5351 - val_accuracy: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6335 - accuracy: 0.8380\n",
      "Epoch 39: loss did not improve from 0.63048\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6336 - accuracy: 0.8380 - val_loss: 12.5367 - val_accuracy: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "642/644 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.8387\n",
      "Epoch 40: loss did not improve from 0.63048\n",
      "644/644 [==============================] - 8s 13ms/step - loss: 0.6315 - accuracy: 0.8386 - val_loss: 12.5353 - val_accuracy: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "644/644 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.8390\n",
      "Epoch 41: loss did not improve from 0.63048\n",
      "644/644 [==============================] - 9s 13ms/step - loss: 0.6321 - accuracy: 0.8390 - val_loss: 12.5393 - val_accuracy: 0.0534 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain,ytrain,epochs=200,validation_data=(xtest,ytest),verbose=1,callbacks= [early_stopping,check_point,tensor_board_visualizations,reduced])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 298620), started 0:16:20 ago. (Use '!kill 298620' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-622fd12ee84f1160\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-622fd12ee84f1160\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"./logs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for next word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model,input_text,max_token_length,tockenize):\n",
    "    input_sequence = tockenize.texts_to_sequences([input_text])[0]\n",
    "    if len(input_sequence)>= max_token_length:\n",
    "        input_sequence = input_sequence[-(max_token_length-1):]\n",
    "    input_sequence = pad_sequences([input_sequence],maxlen=max_token_length-1,padding='pre')\n",
    "    pred = model.predict(input_sequence,verbose=0)\n",
    "    predected_index = np.argmax(pred,axis=1)\n",
    "    for word,index in tockenize.word_index.items():\n",
    "        if predected_index==index:\n",
    "            return word\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'honest'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input =\"To be or not to be\"\n",
    "\n",
    "predict_next_word(model = model,input_text=input,max_token_length= max_sequence_length,tockenize=tockenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\Next Word Prediction using LSTM\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "\n",
    "model.save(\"next_word_lstm.h5\")\n",
    "\n",
    "#save the tockenizer\n",
    "import pickle\n",
    "with open('tokenize.pickel','wb') as handle:\n",
    "    pickle.dump(tockenize,handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = tf.keras.models.load_model(\"next_word_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenize.pickel','rb') as token:    \n",
    "    tok = pickle.load(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Fran. You come most carefully vpon your houre Bar. 'Tis now strook twelue, get thee to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'night'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model = m1,input_text=input,max_token_length=m1.input_shape[1]+1 ,tockenize=tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
